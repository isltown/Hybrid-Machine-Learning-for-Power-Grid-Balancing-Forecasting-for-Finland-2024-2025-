{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_hybrid_modeling\n",
    "\n",
    "**Purpose:** Load preprocessed features, split chronologically, train a baseline hybrid pipeline (classifier + regressor), evaluate, and save final artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report, confusion_matrix, mean_absolute_error, mean_squared_error\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Config\n",
    "PROCESSED_PATH = Path(\"processed/features_ready.csv\")\n",
    "ARTIFACTS_DIR = Path(\"final_artifacts\")\n",
    "MODELS_DIR = ARTIFACTS_DIR / \"models\"\n",
    "PLOTS_DIR = ARTIFACTS_DIR / \"plots\"\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "THRESHOLD = 50.0\n",
    "SPLIT_DATE = pd.Timestamp(\"2025-02-15 23:00:00+00:00\")\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PROCESSED_PATH, index_col=0, parse_dates=True)\n",
    "df.index = df.index.tz_convert(\"UTC\") if df.index.tzinfo is None else df.index\n",
    "print(\"Loaded processed features:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X,y\n",
    "exclude = ['Up_next_hour', 'Up']\n",
    "feature_cols = [c for c in df.columns if c not in exclude]\n",
    "X = df[feature_cols].copy()\n",
    "y = df['Up_next_hour'].copy()\n",
    "\n",
    "# Chronological split\n",
    "train_mask = X.index <= SPLIT_DATE\n",
    "X_train, X_test = X.loc[train_mask], X.loc[~train_mask]\n",
    "y_train, y_test = y.loc[train_mask], y.loc[~train_mask]\n",
    "print(\"Train/Test shapes:\", X_train.shape, X_test.shape)\n",
    "\n",
    "# Event labels\n",
    "y_train_event = (y_train > THRESHOLD).astype(int)\n",
    "y_test_event = (y_test > THRESHOLD).astype(int)\n",
    "print(\"Event rate (train/test):\", y_train_event.mean(), y_test_event.mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline models\n",
    "We will use:\n",
    "- Classifier: XGBoostClassifier (if available) or RandomForestClassifier\n",
    "- Regressor: XGBoostRegressor (if available) or RandomForestRegressor\n",
    "Regressor is trained only on event rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier: try xgboost if installed, else RF\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    clf_model = xgb.XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=5, use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=RANDOM_STATE)\n",
    "    print(\"Using XGBoostClassifier\")\n",
    "except Exception:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    print(\"Using RandomForestClassifier\")\n",
    "\n",
    "clf_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"clf\", clf_model)])\n",
    "clf_pipe.fit(X_train, y_train_event)\n",
    "joblib.dump(clf_pipe, MODELS_DIR / \"classifier_pipe.joblib\")\n",
    "print(\"Classifier trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate classifier on test\n",
    "y_proba = clf_pipe.predict_proba(X_test)[:,1]\n",
    "y_pred_label = (y_proba > 0.5).astype(int)\n",
    "\n",
    "print(\"Classification report (threshold=0.5):\")\n",
    "print(classification_report(y_test_event, y_pred_label, digits=4))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_event, y_proba).round(4))\n",
    "\n",
    "# ROC plot\n",
    "fpr, tpr, _ = roc_curve(y_test_event, y_proba)\n",
    "plt.figure(figsize=(6,5)); plt.plot(fpr, tpr, label=f\"AUC={roc_auc_score(y_test_event,y_proba):.3f}\")\n",
    "plt.plot([0,1],[0,1],'k--', alpha=0.3); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC\"); plt.legend(); plt.grid(alpha=0.2)\n",
    "plt.tight_layout(); plt.savefig(PLOTS_DIR / \"roc_classifier.png\"); plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressor: try xgboost if available, else RF\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    reg_model = xgb.XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=6, n_jobs=-1, random_state=RANDOM_STATE)\n",
    "    print(\"Using XGBoostRegressor\")\n",
    "except Exception:\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    reg_model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "    print(\"Using RandomForestRegressor\")\n",
    "\n",
    "event_mask = y_train > THRESHOLD\n",
    "print(\"Event rows for training regressor:\", event_mask.sum())\n",
    "if event_mask.sum() == 0:\n",
    "    raise RuntimeError(\"No event rows in train set to train regressor on.\")\n",
    "\n",
    "reg_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"reg\", reg_model)])\n",
    "reg_pipe.fit(X_train.loc[event_mask], y_train.loc[event_mask])\n",
    "joblib.dump(reg_pipe, MODELS_DIR / \"regressor_pipe.joblib\")\n",
    "print(\"Regressor trained on event rows and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prob-weighted hybrid\n",
    "reg_pred_all = reg_pipe.predict(X_test)\n",
    "final_pred_pw = y_proba * reg_pred_all\n",
    "final_pred_pw = np.maximum(final_pred_pw, 0.0)\n",
    "\n",
    "# Evaluate\n",
    "mae_pw = mean_absolute_error(y_test, final_pred_pw)\n",
    "rmse_pw = mean_squared_error(y_test, final_pred_pw, squared=False)\n",
    "print(\"Hybrid (prob-weighted) MAE:\", mae_pw, \"RMSE:\", rmse_pw)\n",
    "\n",
    "# MAE on event hours\n",
    "event_mask_test = y_test > THRESHOLD\n",
    "if event_mask_test.sum() > 0:\n",
    "    mae_event = mean_absolute_error(y_test[event_mask_test], final_pred_pw[event_mask_test])\n",
    "    print(\"MAE on true event hours:\", mae_event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "preds = pd.DataFrame({\n",
    "    \"datetime\": X_test.index,\n",
    "    \"y_true\": y_test.values,\n",
    "    \"p_event\": y_proba,\n",
    "    \"pred_prob_weighted\": final_pred_pw\n",
    "}).set_index(\"datetime\")\n",
    "preds.to_csv(ARTIFACTS_DIR / \"hybrid_predictions.csv\")\n",
    "print(\"Saved hybrid predictions to:\", ARTIFACTS_DIR / \"hybrid_predictions.csv\")\n",
    "\n",
    "# Pred vs actual plot\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(preds.index, preds[\"y_true\"], label=\"Actual\", linewidth=1.2)\n",
    "plt.plot(preds.index, preds[\"pred_prob_weighted\"], label=\"Predicted (prob-weighted)\", alpha=0.9)\n",
    "plt.title(\"Hybrid Predicted vs Actual (test)\"); plt.legend(); plt.grid(alpha=0.2)\n",
    "plt.tight_layout(); plt.savefig(PLOTS_DIR / \"hybrid_pred_vs_actual.png\"); plt.close()\n",
    "\n",
    "# Error histogram\n",
    "errors = preds[\"y_true\"] - preds[\"pred_prob_weighted\"]\n",
    "plt.figure(figsize=(6,4)); plt.hist(errors, bins=50); plt.title(\"Error distribution\"); plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / \"hybrid_error_hist.png\"); plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Use Notebook 3 to benchmark other classifier/regressor combos and optimize pipelines.\n",
    "- Consider calibrating classifier probabilities and using log1p transform for regressor target.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
