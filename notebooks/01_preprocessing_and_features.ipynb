{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_preprocessing_and_features\n",
    "\n",
    "**Purpose:** Load raw CSV, perform data quality checks, cleaning, and create features (lags, time features). Save cleaned feature file for modeling.\n",
    "\n",
    "Notes:\n",
    "- Expect the raw CSV to be placed at `data/extended_data_v2.csv` (or update the path).\n",
    "- This notebook produces `processed/features_ready.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Paths\n",
    "RAW_PATH = Path(\"data/extended_data_v2.csv\")   # change if needed\n",
    "PROCESSED_DIR = Path(\"processed\")\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_FEATURES = PROCESSED_DIR / \"features_ready.csv\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "We try Kaggle path first (for convenience), otherwise use local `data/` folder.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flexible loading (works on Kaggle and local)\n",
    "import os\n",
    "if os.path.exists(\"/kaggle/input/finland-afrr-energy-market-and-weather-data/extended_data_v2.csv\"):\n",
    "    raw_path = \"/kaggle/input/finland-afrr-energy-market-and-weather-data/extended_data_v2.csv\"\n",
    "else:\n",
    "    raw_path = RAW_PATH\n",
    "\n",
    "print(\"Loading from:\", raw_path)\n",
    "df = pd.read_csv(raw_path, parse_dates=['datetime'])\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick data quality checks\n",
    "Check basic info, missing values, value ranges and types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data checks\n",
    "display(df.info())\n",
    "display(df.describe(include='all').T)\n",
    "na_counts = df.isna().sum().sort_values(ascending=False)\n",
    "display(na_counts.head(40))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Plan\n",
    "- Ensure datetime is parsed and timezone-localized to UTC\n",
    "- Reindex to a continuous hourly index and forward/backward-fill small gaps\n",
    "- Convert object columns to numeric where appropriate\n",
    "- Replace infinities with NaN\n",
    "- Save a copy of cleaned raw (before feature engineering)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = df.copy()\n",
    "# datetime -> index\n",
    "if 'datetime' in df.columns:\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "    # localize to UTC if naive\n",
    "    if df['datetime'].dt.tz is None:\n",
    "        df['datetime'] = df['datetime'].dt.tz_localize(\"UTC\")\n",
    "    df = df.dropna(subset=['datetime']).set_index('datetime').sort_index()\n",
    "else:\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise RuntimeError(\"No datetime column and index is not DatetimeIndex.\")\n",
    "    if df.index.tz is None:\n",
    "        df.index = df.index.tz_localize(\"UTC\")\n",
    "\n",
    "# reindex hourly and fill tiny gaps\n",
    "full_idx = pd.date_range(start=df.index.min(), end=df.index.max(), freq='H', tz='UTC')\n",
    "missing = full_idx.difference(df.index)\n",
    "print(\"Missing hourly timestamps count:\", len(missing))\n",
    "if len(missing) > 0:\n",
    "    df = df.reindex(full_idx)\n",
    "    df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# coerce object columns to numeric\n",
    "for c in df.columns:\n",
    "    if df[c].dtype == object:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# replace infs\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "print(\"Post-clean shape:\", df.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "Create:\n",
    "- target column `Up_next_hour` (Up shifted -1)\n",
    "- lag features for selected base columns (1,2,3,6,12,24)\n",
    "- time cyclic features (hour_sin/hour_cos), weekday, weekend, month\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TARGET = \"Up\"\n",
    "if TARGET not in df.columns:\n",
    "    raise ValueError(\"Target 'Up' not in dataset.\")\n",
    "\n",
    "# target\n",
    "df['Up_next_hour'] = df[TARGET].shift(-1)\n",
    "\n",
    "# lags\n",
    "LAGS = [1,2,3,6,12,24]\n",
    "lag_base = [c for c in [TARGET, \"electricity_consumption\", \"electricity_consumption_forecast\",\n",
    "                        \"sp\", \"Up_Cap\", \"Down_Cap\", \"air_temperature\", \"wind_speed\"] if c in df.columns]\n",
    "for lag in LAGS:\n",
    "    for c in lag_base:\n",
    "        df[f\"{c}_lag_{lag}\"] = df[c].shift(lag)\n",
    "\n",
    "# time features\n",
    "df['hour'] = df.index.hour\n",
    "df['hour_sin'] = np.sin(2*np.pi*df['hour']/24)\n",
    "df['hour_cos'] = np.cos(2*np.pi*df['hour']/24)\n",
    "df['day_of_week'] = df.index.weekday\n",
    "df['is_weekend'] = df['day_of_week'].isin([5,6]).astype(int)\n",
    "df['month'] = df.index.month\n",
    "if 'is_public_holiday' in df.columns:\n",
    "    df['is_public_holiday'] = pd.to_numeric(df['is_public_holiday'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# drop rows where target or the minimum-lag features are missing\n",
    "before = df.shape[0]\n",
    "df = df.dropna(subset=['Up_next_hour'] + [f\"{c}_lag_{min(LAGS)}\" for c in lag_base], how='any')\n",
    "after = df.shape[0]\n",
    "print(f\"Dropped {before-after} rows due to lag/target NaNs. Remaining rows: {after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed features\n",
    "df.to_csv(OUT_FEATURES)\n",
    "print(\"Saved processed features to:\", OUT_FEATURES)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
