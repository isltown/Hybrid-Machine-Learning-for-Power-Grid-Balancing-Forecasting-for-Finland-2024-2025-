{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03_model_comparison_and_analysis\n",
    "\n",
    "**Purpose:** Systematically benchmark multiple classifier Ã— regressor hybrid combinations, pick the best pair, calibrate classifier, retrain regressor on log1p target, compute permutation importances, and save final artifacts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LogisticRegression, ElasticNet\n",
    "from sklearn.metrics import roc_auc_score, mean_absolute_error, mean_squared_error, roc_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "ARTIFACTS_DIR = Path(\"final_artifacts\")\n",
    "PLOTS_DIR = ARTIFACTS_DIR / \"plots\"\n",
    "PROCESSED_PATH = Path(\"processed/features_ready.csv\")\n",
    "RANDOM_STATE = 42\n",
    "THRESHOLD = 50.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PROCESSED_PATH, index_col=0, parse_dates=True)\n",
    "exclude = ['Up_next_hour', 'Up']\n",
    "X = df[[c for c in df.columns if c not in exclude]].copy()\n",
    "y = df['Up_next_hour'].copy()\n",
    "\n",
    "SPLIT_DATE = pd.Timestamp(\"2025-02-15 23:00:00+00:00\")\n",
    "train_mask = X.index <= SPLIT_DATE\n",
    "X_train, X_test = X.loc[train_mask], X.loc[~train_mask]\n",
    "y_train, y_test = y.loc[train_mask], y.loc[~train_mask]\n",
    "y_train_event = (y_train > THRESHOLD).astype(int)\n",
    "y_test_event = (y_test > THRESHOLD).astype(int)\n",
    "print(\"Loaded data. Train/Test shapes:\", X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate classifiers and regressors\n",
    "We'll try:\n",
    "- Classifiers: XGBoost (if available), RandomForest, LogisticRegression\n",
    "- Regressors: XGBoost (if available), RandomForestReg, GradientBoosting, ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try xgboost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_AVAILABLE = True\n",
    "except Exception:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "classifiers = []\n",
    "if XGB_AVAILABLE:\n",
    "    classifiers.append((\"XGBClassifier\", lambda: xgb.XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=RANDOM_STATE)))\n",
    "classifiers += [\n",
    "    (\"RandomForest\", lambda: RandomForestClassifier(n_estimators=200, max_depth=10, n_jobs=-1, random_state=RANDOM_STATE)),\n",
    "    (\"LogisticRegression\", lambda: LogisticRegression(max_iter=1000, solver='liblinear'))\n",
    "]\n",
    "\n",
    "regressors = []\n",
    "if XGB_AVAILABLE:\n",
    "    regressors.append((\"XGBRegressor\", lambda: xgb.XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=6, n_jobs=-1, random_state=RANDOM_STATE)))\n",
    "regressors += [\n",
    "    (\"RandomForestReg\", lambda: RandomForestRegressor(n_estimators=200, max_depth=10, n_jobs=-1, random_state=RANDOM_STATE)),\n",
    "    (\"GradientBoosting\", lambda: GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, max_depth=6, random_state=RANDOM_STATE)),\n",
    "    (\"ElasticNet\", lambda: ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000, random_state=RANDOM_STATE))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_models = {}\n",
    "for name, ctor in classifiers:\n",
    "    print(\"Training classifier:\", name)\n",
    "    pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"clf\", ctor())])\n",
    "    pipe.fit(X_train, y_train_event)\n",
    "    y_proba = pipe.predict_proba(X_test)[:,1]\n",
    "    roc = roc_auc_score(y_test_event, y_proba)\n",
    "    clf_models[name] = {\"pipe\": pipe, \"proba\": y_proba, \"roc_auc\": roc}\n",
    "    print(\" ROC-AUC:\", roc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_models = {}\n",
    "event_mask = y_train > THRESHOLD\n",
    "n_events = event_mask.sum()\n",
    "print(\"Event rows in train:\", n_events)\n",
    "for name, ctor in regressors:\n",
    "    if n_events < 10:\n",
    "        print(\"Skipping regressor\", name, \"due to too few events.\")\n",
    "        continue\n",
    "    print(\"Training regressor:\", name)\n",
    "    pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"reg\", ctor())])\n",
    "    pipe.fit(X_train.loc[event_mask], y_train.loc[event_mask].values)\n",
    "    train_preds = pipe.predict(X_train.loc[event_mask])\n",
    "    train_mae = mean_absolute_error(y_train.loc[event_mask], train_preds)\n",
    "    reg_models[name] = {\"pipe\": pipe, \"train_mae\": train_mae}\n",
    "    print(\" Train-event MAE:\", train_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for clf_name, clf_info in clf_models.items():\n",
    "    y_proba = clf_info[\"proba\"]\n",
    "    for reg_name, reg_info in reg_models.items():\n",
    "        reg_pipe = reg_info[\"pipe\"]\n",
    "        reg_pred_all = reg_pipe.predict(X_test)\n",
    "        pw_pred = y_proba * reg_pred_all\n",
    "        mae_pw = mean_absolute_error(y_test, pw_pred)\n",
    "        rmse_pw = mean_squared_error(y_test, pw_pred, squared=False)\n",
    "        # hard50\n",
    "        hard_mask = y_proba > 0.5\n",
    "        hard_pred = np.zeros_like(y_test.values, dtype=float)\n",
    "        if hard_mask.sum() > 0:\n",
    "            hard_pred[hard_mask] = reg_pred_all[hard_mask]\n",
    "        mae_hard = mean_absolute_error(y_test, hard_pred)\n",
    "        # best threshold search\n",
    "        best_th, best_mae = None, np.inf\n",
    "        for th in np.linspace(0,1,101):\n",
    "            mask_th = y_proba > th\n",
    "            p = np.zeros_like(y_test.values, dtype=float)\n",
    "            if mask_th.sum() > 0:\n",
    "                p[mask_th] = reg_pred_all[mask_th]\n",
    "            m = mean_absolute_error(y_test, p)\n",
    "            if m < best_mae:\n",
    "                best_mae = m\n",
    "                best_th = th\n",
    "        # reg metrics on true events\n",
    "        true_mask = y_test > THRESHOLD\n",
    "        reg_test_mae = np.nan\n",
    "        if true_mask.sum() > 0:\n",
    "            reg_test_mae = mean_absolute_error(y_test[true_mask], reg_pred_all[true_mask])\n",
    "        results.append({\n",
    "            \"classifier\": clf_name,\n",
    "            \"classifier_roc_auc\": clf_info[\"roc_auc\"],\n",
    "            \"regressor\": reg_name,\n",
    "            \"reg_train_mae_on_events\": reg_info[\"train_mae\"],\n",
    "            \"reg_test_mae_on_events\": reg_test_mae,\n",
    "            \"prob_weighted_mae\": mae_pw,\n",
    "            \"prob_weighted_rmse\": rmse_pw,\n",
    "            \"hard50_mae\": mae_hard,\n",
    "            \"best_th\": best_th,\n",
    "            \"best_th_mae\": best_mae\n",
    "        })\n",
    "        print(f\"{clf_name} + {reg_name}: PW MAE {mae_pw:.3f}, hard50 MAE {mae_hard:.3f}, best_th {best_th:.2f} (MAE {best_mae:.3f})\")\n",
    "\n",
    "summary_df = pd.DataFrame(results).sort_values(\"prob_weighted_mae\").reset_index(drop=True)\n",
    "summary_df.to_csv(ARTIFACTS_DIR / \"hybrid_model_comparison.csv\", index=False)\n",
    "display(summary_df.head(10))\n",
    "print(\"Saved hybrid_model_comparison.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the best performing combo and retrain final pipelines with calibration & log1p regressor\n",
    "We will:\n",
    "- pick the top combo (lowest prob_weighted_mae),\n",
    "- calibrate classifier probabilities (isotonic),\n",
    "- retrain regressor on log1p(Up) for event rows and back-transform predictions,\n",
    "- save final artifacts and compute final metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick best\n",
    "best_row = summary_df.iloc[0]\n",
    "best_clf = best_row['classifier']\n",
    "best_reg = best_row['regressor']\n",
    "print(\"Best combo:\", best_clf, \"+\", best_reg)\n",
    "\n",
    "best_clf_pipe = clf_models[best_clf]['pipe']\n",
    "best_reg_pipe = reg_models[best_reg]['pipe']\n",
    "\n",
    "# calibrate classifier\n",
    "raw_clf = best_clf_pipe.named_steps['clf']\n",
    "cal = CalibratedClassifierCV(raw_clf, cv=5, method='isotonic')\n",
    "clf_cal_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"cal\", cal)])\n",
    "clf_cal_pipe.fit(X_train, y_train_event)\n",
    "y_proba_cal = clf_cal_pipe.predict_proba(X_test)[:,1]\n",
    "print(\"Calibrated ROC-AUC:\", roc_auc_score(y_test_event, y_proba_cal).round(4))\n",
    "\n",
    "# retrain regressor on log1p\n",
    "event_mask_train = y_train > THRESHOLD\n",
    "if event_mask_train.sum() == 0:\n",
    "    raise RuntimeError(\"No event rows for regressor retrain.\")\n",
    "# try to reuse same regressor class\n",
    "RegCtor = reg_models[best_reg]['pipe'].named_steps['reg'].__class__\n",
    "try:\n",
    "    reg_params = reg_models[best_reg]['pipe'].named_steps['reg'].get_params()\n",
    "    reg_final = RegCtor(**{k:v for k,v in reg_params.items() if k in RegCtor().get_params()})\n",
    "except Exception:\n",
    "    reg_final = RegCtor()\n",
    "reg_pipe_log = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"reg\", reg_final)])\n",
    "y_train_log = np.log1p(y_train.loc[event_mask_train])\n",
    "reg_pipe_log.fit(X_train.loc[event_mask_train], y_train_log)\n",
    "joblib.dump(clf_cal_pipe, ARTIFACTS_DIR / \"classifier_calibrated.joblib\")\n",
    "joblib.dump(reg_pipe_log, ARTIFACTS_DIR / \"regressor_log1p.joblib\")\n",
    "print(\"Saved calibrated classifier and log-regressor.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final preds\n",
    "y_proba_final = clf_cal_pipe.predict_proba(X_test)[:,1]\n",
    "reg_pred_log = reg_pipe_log.predict(X_test)\n",
    "reg_pred = np.expm1(reg_pred_log).clip(0)\n",
    "hybrid_pw = y_proba_final * reg_pred\n",
    "\n",
    "mae_pw = mean_absolute_error(y_test, hybrid_pw)\n",
    "rmse_pw = mean_squared_error(y_test, hybrid_pw, squared=False)\n",
    "print(\"Final prob-weighted MAE:\", mae_pw, \"RMSE:\", rmse_pw)\n",
    "\n",
    "# save predictions\n",
    "final_preds = pd.DataFrame({\n",
    "    \"datetime\": X_test.index,\n",
    "    \"y_true\": y_test.values,\n",
    "    \"p_event\": y_proba_final,\n",
    "    \"pred_prob_weighted\": hybrid_pw\n",
    "}).set_index(\"datetime\")\n",
    "final_preds.to_csv(ARTIFACTS_DIR / \"final_hybrid_predictions.csv\")\n",
    "print(\"Saved final_hybrid_predictions.csv\")\n",
    "\n",
    "# permutation importances (warning: can be slow)\n",
    "clf_imp = permutation_importance(clf_cal_pipe, X_test, y_test_event, n_repeats=16, random_state=RANDOM_STATE, scoring='roc_auc', n_jobs=-1)\n",
    "clf_imp_df = pd.DataFrame({\"feature\": X_test.columns, \"mean_decrease_auc\": clf_imp.importances_mean}).sort_values(\"mean_decrease_auc\", ascending=False)\n",
    "clf_imp_df.head(20).to_csv(ARTIFACTS_DIR / \"classifier_permutation_importance.csv\", index=False)\n",
    "\n",
    "reg_imp = permutation_importance(reg_pipe_log, X_test, np.expm1(reg_pipe_log.predict(X_test)), n_repeats=16, random_state=RANDOM_STATE, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "reg_imp_df = pd.DataFrame({\"feature\": X_test.columns, \"mean_decrease_negMAE\": reg_imp.importances_mean})\n",
    "reg_imp_df[\"mean_increase_MAE\"] = -reg_imp_df[\"mean_decrease_negMAE\"]\n",
    "reg_imp_df = reg_imp_df.sort_values(\"mean_increase_MAE\", ascending=False)\n",
    "reg_imp_df.head(20).to_csv(ARTIFACTS_DIR / \"regressor_permutation_importance.csv\", index=False)\n",
    "print(\"Saved permutation importances.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-up\n",
    "- All artifacts saved to `final_artifacts/`.\n",
    "- Inspect `hybrid_model_comparison.csv`, `final_hybrid_predictions.csv`, and permutation importance CSVs for reporting and README visuals.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0 (v3.11.0:deaf509e8f, Oct 24 2022, 14:43:23) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
